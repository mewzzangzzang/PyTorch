{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "# 변수 선언   \n",
    "x_train=torch.FloatTensor([[1],[2],[3],[4],[5]])\n",
    "y_train=torch.FloatTensor([[3],[5],[7],[9],[11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4414], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "model=nn.Linear(1,1)\n",
    "# input_dim, output_dim\n",
    "print(list(model.parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD-확률적 경사하강법 lr 러닝데이터\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 0 Cost= 39.16685104370117\n",
      "Epoch= 100 Cost= 0.08463062345981598\n",
      "Epoch= 200 Cost= 0.04298952594399452\n",
      "Epoch= 300 Cost= 0.021837208420038223\n",
      "Epoch= 400 Cost= 0.01109258271753788\n",
      "Epoch= 500 Cost= 0.00563468411564827\n",
      "Epoch= 600 Cost= 0.0028622171375900507\n",
      "Epoch= 700 Cost= 0.0014539161929860711\n",
      "Epoch= 800 Cost= 0.0007385412463918328\n",
      "Epoch= 900 Cost= 0.00037515218718908727\n",
      "Epoch= 1000 Cost= 0.00019056595920119435\n",
      "Epoch= 1100 Cost= 9.680409129941836e-05\n",
      "Epoch= 1200 Cost= 4.91717473778408e-05\n",
      "Epoch= 1300 Cost= 2.497919740562793e-05\n",
      "Epoch= 1400 Cost= 1.2689983122982085e-05\n",
      "Epoch= 1500 Cost= 6.447205578297144e-06\n",
      "Epoch= 1600 Cost= 3.276181814726442e-06\n",
      "Epoch= 1700 Cost= 1.6654261116855196e-06\n",
      "Epoch= 1800 Cost= 8.460160643153358e-07\n",
      "Epoch= 1900 Cost= 4.302897309571563e-07\n",
      "Epoch= 2000 Cost= 2.1860606125301274e-07\n",
      "Epoch= 2100 Cost= 1.1113379372318377e-07\n",
      "Epoch= 2200 Cost= 5.657594925878584e-08\n",
      "Epoch= 2300 Cost= 2.86554158179797e-08\n",
      "Epoch= 2400 Cost= 1.4702209227834828e-08\n",
      "Epoch= 2500 Cost= 7.451364858468423e-09\n",
      "Epoch= 2600 Cost= 3.771356116288871e-09\n",
      "Epoch= 2700 Cost= 1.905709812177747e-09\n",
      "Epoch= 2800 Cost= 9.986707016906848e-10\n",
      "Epoch= 2900 Cost= 5.25824384034479e-10\n",
      "Epoch= 3000 Cost= 2.9467628337442875e-10\n",
      "Epoch= 3100 Cost= 1.63220187365809e-10\n",
      "Epoch= 3200 Cost= 1.0809344391793374e-10\n",
      "Epoch= 3300 Cost= 6.230038707144558e-11\n",
      "Epoch= 3400 Cost= 5.426272625674855e-11\n",
      "Epoch= 3500 Cost= 5.426272625674855e-11\n",
      "Epoch= 3600 Cost= 5.426272625674855e-11\n",
      "Epoch= 3700 Cost= 5.426272625674855e-11\n",
      "Epoch= 3800 Cost= 5.426272625674855e-11\n",
      "Epoch= 3900 Cost= 5.426272625674855e-11\n",
      "Epoch= 4000 Cost= 5.426272625674855e-11\n",
      "Epoch= 4100 Cost= 5.426272625674855e-11\n",
      "Epoch= 4200 Cost= 5.426272625674855e-11\n",
      "Epoch= 4300 Cost= 5.426272625674855e-11\n",
      "Epoch= 4400 Cost= 5.426272625674855e-11\n",
      "Epoch= 4500 Cost= 5.426272625674855e-11\n",
      "Epoch= 4600 Cost= 5.426272625674855e-11\n",
      "Epoch= 4700 Cost= 5.426272625674855e-11\n",
      "Epoch= 4800 Cost= 5.426272625674855e-11\n",
      "Epoch= 4900 Cost= 5.426272625674855e-11\n",
      "Epoch= 5000 Cost= 5.426272625674855e-11\n",
      "Epoch= 5100 Cost= 5.426272625674855e-11\n",
      "Epoch= 5200 Cost= 5.426272625674855e-11\n",
      "Epoch= 5300 Cost= 5.426272625674855e-11\n",
      "Epoch= 5400 Cost= 5.426272625674855e-11\n",
      "Epoch= 5500 Cost= 5.426272625674855e-11\n",
      "Epoch= 5600 Cost= 5.426272625674855e-11\n",
      "Epoch= 5700 Cost= 5.426272625674855e-11\n",
      "Epoch= 5800 Cost= 5.426272625674855e-11\n",
      "Epoch= 5900 Cost= 5.426272625674855e-11\n",
      "Epoch= 6000 Cost= 5.426272625674855e-11\n",
      "Epoch= 6100 Cost= 5.426272625674855e-11\n",
      "Epoch= 6200 Cost= 5.426272625674855e-11\n",
      "Epoch= 6300 Cost= 5.426272625674855e-11\n",
      "Epoch= 6400 Cost= 5.426272625674855e-11\n",
      "Epoch= 6500 Cost= 5.426272625674855e-11\n",
      "Epoch= 6600 Cost= 5.426272625674855e-11\n",
      "Epoch= 6700 Cost= 5.426272625674855e-11\n",
      "Epoch= 6800 Cost= 5.426272625674855e-11\n",
      "Epoch= 6900 Cost= 5.426272625674855e-11\n",
      "Epoch= 7000 Cost= 5.426272625674855e-11\n",
      "Epoch= 7100 Cost= 5.426272625674855e-11\n",
      "Epoch= 7200 Cost= 5.426272625674855e-11\n",
      "Epoch= 7300 Cost= 5.426272625674855e-11\n",
      "Epoch= 7400 Cost= 5.426272625674855e-11\n",
      "Epoch= 7500 Cost= 5.426272625674855e-11\n",
      "Epoch= 7600 Cost= 5.426272625674855e-11\n",
      "Epoch= 7700 Cost= 5.426272625674855e-11\n",
      "Epoch= 7800 Cost= 5.426272625674855e-11\n",
      "Epoch= 7900 Cost= 5.426272625674855e-11\n",
      "Epoch= 8000 Cost= 5.426272625674855e-11\n",
      "Epoch= 8100 Cost= 5.426272625674855e-11\n",
      "Epoch= 8200 Cost= 5.426272625674855e-11\n",
      "Epoch= 8300 Cost= 5.426272625674855e-11\n",
      "Epoch= 8400 Cost= 5.426272625674855e-11\n",
      "Epoch= 8500 Cost= 5.426272625674855e-11\n",
      "Epoch= 8600 Cost= 5.426272625674855e-11\n",
      "Epoch= 8700 Cost= 5.426272625674855e-11\n",
      "Epoch= 8800 Cost= 5.426272625674855e-11\n",
      "Epoch= 8900 Cost= 5.426272625674855e-11\n",
      "Epoch= 9000 Cost= 5.426272625674855e-11\n",
      "Epoch= 9100 Cost= 5.426272625674855e-11\n",
      "Epoch= 9200 Cost= 5.426272625674855e-11\n",
      "Epoch= 9300 Cost= 5.426272625674855e-11\n",
      "Epoch= 9400 Cost= 5.426272625674855e-11\n",
      "Epoch= 9500 Cost= 5.426272625674855e-11\n",
      "Epoch= 9600 Cost= 5.426272625674855e-11\n",
      "Epoch= 9700 Cost= 5.426272625674855e-11\n",
      "Epoch= 9800 Cost= 5.426272625674855e-11\n",
      "Epoch= 9900 Cost= 5.426272625674855e-11\n",
      "Epoch= 10000 Cost= 5.426272625674855e-11\n",
      "Epoch= 10100 Cost= 5.426272625674855e-11\n",
      "Epoch= 10200 Cost= 5.426272625674855e-11\n",
      "Epoch= 10300 Cost= 5.426272625674855e-11\n",
      "Epoch= 10400 Cost= 5.426272625674855e-11\n",
      "Epoch= 10500 Cost= 5.426272625674855e-11\n",
      "Epoch= 10600 Cost= 5.426272625674855e-11\n",
      "Epoch= 10700 Cost= 5.426272625674855e-11\n",
      "Epoch= 10800 Cost= 5.426272625674855e-11\n",
      "Epoch= 10900 Cost= 5.426272625674855e-11\n",
      "Epoch= 11000 Cost= 5.426272625674855e-11\n",
      "Epoch= 11100 Cost= 5.426272625674855e-11\n",
      "Epoch= 11200 Cost= 5.426272625674855e-11\n",
      "Epoch= 11300 Cost= 5.426272625674855e-11\n",
      "Epoch= 11400 Cost= 5.426272625674855e-11\n",
      "Epoch= 11500 Cost= 5.426272625674855e-11\n",
      "Epoch= 11600 Cost= 5.426272625674855e-11\n",
      "Epoch= 11700 Cost= 5.426272625674855e-11\n",
      "Epoch= 11800 Cost= 5.426272625674855e-11\n",
      "Epoch= 11900 Cost= 5.426272625674855e-11\n",
      "Epoch= 12000 Cost= 5.426272625674855e-11\n",
      "Epoch= 12100 Cost= 5.426272625674855e-11\n",
      "Epoch= 12200 Cost= 5.426272625674855e-11\n",
      "Epoch= 12300 Cost= 5.426272625674855e-11\n",
      "Epoch= 12400 Cost= 5.426272625674855e-11\n",
      "Epoch= 12500 Cost= 5.426272625674855e-11\n",
      "Epoch= 12600 Cost= 5.426272625674855e-11\n",
      "Epoch= 12700 Cost= 5.426272625674855e-11\n",
      "Epoch= 12800 Cost= 5.426272625674855e-11\n",
      "Epoch= 12900 Cost= 5.426272625674855e-11\n",
      "Epoch= 13000 Cost= 5.426272625674855e-11\n",
      "Epoch= 13100 Cost= 5.426272625674855e-11\n",
      "Epoch= 13200 Cost= 5.426272625674855e-11\n",
      "Epoch= 13300 Cost= 5.426272625674855e-11\n",
      "Epoch= 13400 Cost= 5.426272625674855e-11\n",
      "Epoch= 13500 Cost= 5.426272625674855e-11\n",
      "Epoch= 13600 Cost= 5.426272625674855e-11\n",
      "Epoch= 13700 Cost= 5.426272625674855e-11\n",
      "Epoch= 13800 Cost= 5.426272625674855e-11\n",
      "Epoch= 13900 Cost= 5.426272625674855e-11\n",
      "Epoch= 14000 Cost= 5.426272625674855e-11\n",
      "Epoch= 14100 Cost= 5.426272625674855e-11\n",
      "Epoch= 14200 Cost= 5.426272625674855e-11\n",
      "Epoch= 14300 Cost= 5.426272625674855e-11\n",
      "Epoch= 14400 Cost= 5.426272625674855e-11\n",
      "Epoch= 14500 Cost= 5.426272625674855e-11\n",
      "Epoch= 14600 Cost= 5.426272625674855e-11\n",
      "Epoch= 14700 Cost= 5.426272625674855e-11\n",
      "Epoch= 14800 Cost= 5.426272625674855e-11\n",
      "Epoch= 14900 Cost= 5.426272625674855e-11\n",
      "Epoch= 15000 Cost= 5.426272625674855e-11\n",
      "Epoch= 15100 Cost= 5.426272625674855e-11\n",
      "Epoch= 15200 Cost= 5.426272625674855e-11\n",
      "Epoch= 15300 Cost= 5.426272625674855e-11\n",
      "Epoch= 15400 Cost= 5.426272625674855e-11\n",
      "Epoch= 15500 Cost= 5.426272625674855e-11\n",
      "Epoch= 15600 Cost= 5.426272625674855e-11\n",
      "Epoch= 15700 Cost= 5.426272625674855e-11\n",
      "Epoch= 15800 Cost= 5.426272625674855e-11\n",
      "Epoch= 15900 Cost= 5.426272625674855e-11\n",
      "Epoch= 16000 Cost= 5.426272625674855e-11\n",
      "Epoch= 16100 Cost= 5.426272625674855e-11\n",
      "Epoch= 16200 Cost= 5.426272625674855e-11\n",
      "Epoch= 16300 Cost= 5.426272625674855e-11\n",
      "Epoch= 16400 Cost= 5.426272625674855e-11\n",
      "Epoch= 16500 Cost= 5.426272625674855e-11\n",
      "Epoch= 16600 Cost= 5.426272625674855e-11\n",
      "Epoch= 16700 Cost= 5.426272625674855e-11\n",
      "Epoch= 16800 Cost= 5.426272625674855e-11\n",
      "Epoch= 16900 Cost= 5.426272625674855e-11\n",
      "Epoch= 17000 Cost= 5.426272625674855e-11\n",
      "Epoch= 17100 Cost= 5.426272625674855e-11\n",
      "Epoch= 17200 Cost= 5.426272625674855e-11\n",
      "Epoch= 17300 Cost= 5.426272625674855e-11\n",
      "Epoch= 17400 Cost= 5.426272625674855e-11\n",
      "Epoch= 17500 Cost= 5.426272625674855e-11\n",
      "Epoch= 17600 Cost= 5.426272625674855e-11\n",
      "Epoch= 17700 Cost= 5.426272625674855e-11\n",
      "Epoch= 17800 Cost= 5.426272625674855e-11\n",
      "Epoch= 17900 Cost= 5.426272625674855e-11\n",
      "Epoch= 18000 Cost= 5.426272625674855e-11\n",
      "Epoch= 18100 Cost= 5.426272625674855e-11\n",
      "Epoch= 18200 Cost= 5.426272625674855e-11\n",
      "Epoch= 18300 Cost= 5.426272625674855e-11\n",
      "Epoch= 18400 Cost= 5.426272625674855e-11\n",
      "Epoch= 18500 Cost= 5.426272625674855e-11\n",
      "Epoch= 18600 Cost= 5.426272625674855e-11\n",
      "Epoch= 18700 Cost= 5.426272625674855e-11\n",
      "Epoch= 18800 Cost= 5.426272625674855e-11\n",
      "Epoch= 18900 Cost= 5.426272625674855e-11\n",
      "Epoch= 19000 Cost= 5.426272625674855e-11\n",
      "Epoch= 19100 Cost= 5.426272625674855e-11\n",
      "Epoch= 19200 Cost= 5.426272625674855e-11\n",
      "Epoch= 19300 Cost= 5.426272625674855e-11\n",
      "Epoch= 19400 Cost= 5.426272625674855e-11\n",
      "Epoch= 19500 Cost= 5.426272625674855e-11\n",
      "Epoch= 19600 Cost= 5.426272625674855e-11\n",
      "Epoch= 19700 Cost= 5.426272625674855e-11\n",
      "Epoch= 19800 Cost= 5.426272625674855e-11\n",
      "Epoch= 19900 Cost= 5.426272625674855e-11\n",
      "Epoch= 20000 Cost= 5.426272625674855e-11\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20001):\n",
    "  predict=model(x_train)\n",
    "  # error의 제곱으로 손실\n",
    "  cost=F.mse_loss(predict,y_train)\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "  # 초기화\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  if epoch % 100==0:\n",
    "    print('Epoch=',epoch,'Cost=',cost.item())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[2.0000]], requires_grad=True), Parameter containing:\n",
      "tensor([1.0000], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15.0000],\n",
       "        [19.0000]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.FloatTensor([[7],[9]]))\n",
    "# t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "  def __init__(self): #모델 정의 \n",
    "    super().__init__()\n",
    "    self.linear=nn.Linear(1,1)\n",
    "\n",
    "    # 실행\n",
    "  def forward(self,x):\n",
    "    return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LinearRegressionModel()\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost tensor(102.3972, grad_fn=<MseLossBackward0>)\n",
      "Epoch 400 cost tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "Epoch 800 cost tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "Epoch 1200 cost tensor(7.9607e-06, grad_fn=<MseLossBackward0>)\n",
      "Epoch 1600 cost tensor(5.3039e-07, grad_fn=<MseLossBackward0>)\n",
      "Epoch 2000 cost tensor(3.5386e-08, grad_fn=<MseLossBackward0>)\n",
      "Epoch 2400 cost tensor(2.4144e-09, grad_fn=<MseLossBackward0>)\n",
      "Epoch 2800 cost tensor(1.8708e-10, grad_fn=<MseLossBackward0>)\n",
      "Epoch 3200 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 3600 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 4000 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 4400 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 4800 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 5200 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 5600 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 6000 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 6400 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 6800 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 7200 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 7600 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 8000 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 8400 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 8800 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 9200 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 9600 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 10000 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 10400 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 10800 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 11200 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 11600 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 12000 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 12400 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 12800 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 13200 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 13600 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 14000 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 14400 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 14800 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 15200 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 15600 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 16000 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 16400 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 16800 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 17200 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 17600 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 18000 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 18400 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 18800 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 19200 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 19600 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n",
      "Epoch 20000 cost tensor(7.6443e-11, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20001):\n",
    "  prediction=model(x_train)\n",
    "  cost=F.mse_loss(prediction,y_train)\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "\n",
    "  optimizer.step()\n",
    "\n",
    "  if epoch % 400 ==0:\n",
    "    print('Epoch',epoch,'cost',cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
